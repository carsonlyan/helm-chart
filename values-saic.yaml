kubernetesType: saic # (aws|azure|minikube|saic)

nodeGroupLabel: agentType
  
defineResources: false

components:
  logging: true
  git: false
  gitea: false
  jenkins: false
  superset: true
  hdfs: true
  dnsAutoScaler: false

registry:
  url: https://cr.console.aliyun.com/repository/cn-hangzhou/msc-software/
  repository: registry.cn-hangzhou.aliyuncs.com/msc-software
  secret:
    name: scale-registry
    user: kaycloudtest
    password: likai625

ingress:
  domain: local.scale-hexagon.com
  tls:
    enabled: true
    email: changeme
  services:
    - name: admin
      service: admin
      port: 80
    - name: spark
      service: sparkmaster
      port: 8080
    - name: jupyter
      service: jupyter
      port: 8000
    - name: livy
      service: livy
      port: 8998
    - name: logs
      service: kibana-logging
      port: 5601
    - name: jenkins
      service: jenkins
      port: 8080
    - name: superset
      service: superset
      port: 8088
    - name: gitea
      service: gitea
      port: 3000    

  # auth: 
  #   message: MSC Internal Only
  #   value: scale:$apr1$vMBm2rHD$XNucU3s559l2Lw4s0Z5pV. # created with: htpasswd -nb scale dev
  
  # to change at runtime, 
  # kubectl annotate ingress/scale-ingress nginx.ingress.kubernetes.io/whitelist-source-range=24.20.53.58/32 --overwrite
  # kubectl annotate ingress/scale-ingress-hdfs nginx.ingress.kubernetes.io/whitelist-source-range=24.20.53.58/32 --overwrite  
  # if you get a 403, try getting logs from nginx-ingress-controller
  # whitelist: 192.168.39.1/32 

openId:
  url: http://10.135.3.9:30090/auth/realms/VTDScale
  clientId: gatekeeper
  clientSecret: 82ae4e3a-e696-4564-a4b2-61103e129e51
  encryptionKey: vGcLt8ZUdPX5fXhtLZaPHZkGWHZrT6aa
  group: my-app

imageTag : 0.1.2-172cd576
imagePullPolicy: IfNotPresent

imageAdmin: scale-admin
imageCollector: scale-collector
imageDemodataAdams: scale-demodata-adams
imageDemodataVtd: scale-demodata
imageGit: scale-git
imageJenkins: scale-jenkins
imageScaleServices: scale-services
imageSparkCommon: scale-spark

jenkins:
  pv:
    size: 10G
    class: csi-rbd-sc

jupyter:
  pv:
    size: 100G
    class: csi-rbd-sc

hdfs:
  nfsIP: 10.0.0.18
  pvcClass: csi-rbd-sc 
  
  dn:
    scale: 5
    size: 500G
  nn:
    size: 20G

apm:
  image:
    registry: docker.elastic.co
    repository: apm/apm-server
    version: 7.5.1

curator:
  image:
    registry: docker.io
    repository: library/python
    version: 3.6-alpine

elasticsearch:
  pv:
    size: 100G
    class: csi-rbd-sc
  image:
    registry: docker.elastic.co
    repository: elasticsearch/elasticsearch
    version: 7.5.1

alpine:
  image:
    registry: docker.io
    repository: library/alpine
    version: 3.6    

filebeat:
  image:
    registry: docker.elastic.co
    repository: beats/filebeat
    version: 7.5.1

gatekeeper:
  image:
    registry: docker.io
    repository: carlosedp/keycloak-gatekeeper
    version: v9.0.0

kibana:
  image:
    registry: docker.elastic.co
    repository: kibana/kibana
    version: 7.5.1

kubeStateMetrics:
  image:
    registry: quay.io
    repository: coreos/kube-state-metrics
    version: 1.9.7

ingressController:
  image:
    registry: quay.io
    repository: kubernetes-ingress-controller/nginx-ingress-controller
    version: master

logstash:
  image:
    registry: docker.elastic.co
    repository: logstash/logstash
    version: 7.5.1

metricbeat:
  image:
    registry: docker.elastic.co
    repository: beats/metricbeat  
    version: 7.5.1

gitea:
  pv:
    sizeDb: 10G
    sizeData: 10G
    class: csi-rbd-sc
  image:
    registry: docker.io
    repository: gitea/gitea
    version: 1.8.3

mariadb:
  image:
    registry: docker.io
    repository: library/mariadb    
    version: 10

dnsAutoScaler:
  image:
    registry: k8s.gcr.io
    repository: cluster-proportional-autoscaler-amd64
    version: 1.6.0

superset:
  pv:
    sizeDb: 1G
    class: csi-rbd-sc
  image:
    registry: docker.io
    repository: amancevice/superset
    version: 0.37.0

licensing:
  key: unknown
  clusterId: unknown

# nodeSelector and tolerations for kafka and zookeeper must use defaults here
# be updated for Azure and AWS in build.gradle just lilke kafka.global.imageRegistry
kafka:
  clusterDomain: k8s.saicstack.com
  global:
    imageRegistry: docker.io
    imagePullSecrets: []
  kafka:
    fullname: kafka
  replicaCount: 3
  deleteTopicEnable: true
  logRetentionHours: 8760
  nodeSelector: {"agentType": "core"}
  tolerations: [{"key": "scale", "operator": "Exists", "effect": "NoSchedule"}]
  affinity: {"podAntiAffinity": {"preferredDuringSchedulingIgnoredDuringExecution": [{"weight": 100, "podAffinityTerm": {"labelSelector": {"matchExpressions": [{"key": "app.kubernetes.io/component", "operator": "In", "values":['kafka']}]}, "topologyKey": "kubernetes.io/hostname"}}]}}
  zookeeper:
    nodeSelector: {"agentType": "core"}
    tolerations: [{"key": "scale", "operator": "Exists", "effect": "NoSchedule"}]
